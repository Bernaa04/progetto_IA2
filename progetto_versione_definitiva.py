# -*- coding: utf-8 -*-
"""Progetto - Versione definitiva

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iw9GTPvqTji-1qtcpWicqe8fMh9tWhfp

# Progetto IA II: Classificazione

## Librerie
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import fbeta_score
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import f1_score

"""## Caricamento del dataset


"""

# Carichiamo il dataset e visualizziamo il numero e il formato delle features:
dataset_path = "https://raw.githubusercontent.com/Bernaa04/progetto_IA2/refs/heads/main/WA_Fn-UseC_-Telco-Customer-Churn.csv"
data = pd.read_csv(dataset_path)
data.info()

data.head()

"""## Preprocessing & feature engneering

### Pulizia del dataset
"""

# Due osservazioni iniziali:

# 1. La feature "customerID" non ha alcuna rilevanza ai fini della classificazione, decidiamo di rimuoverla;
if "customerID" in data.columns: data.drop(columns=["customerID"], inplace=True)

# 2. La feature "TotalCharges" è il prodotto di "MonthlyCharges" e "tenure": mantenere tutte e tre potrebbe causare multicollinearità. Pertanto, decidiamo di rimuoverla;
if "TotalCharges" in data.columns: data.drop(columns=["TotalCharges"], inplace=True)

# Procediamo con l'individuazione della variabile target e procediamo con la sua conversione in numerico(dall'attuale datatype object)
data["Churn"] = (data["Churn"] == "Yes").astype(int)

# Nonostante la prima verifica fatta con data.info(), per assicurarci che non vi sia nessun valore nullo, decidiamo di procedere con una verifica più approfondita;
valori_nulli = ["", "none", "n/a", "na", "null", "?"]
print("RICERCA VALORI NULLI - dtype object:")
print(data.select_dtypes(include="object").apply(lambda x: x.astype(str).str.strip().str.lower().isin(valori_nulli).sum()))
print("\n")
print("RICERCA VALORI NULLI - dtype numerico:")
print(data.isna().sum())

"""### One-hot encoding"""

# Il passo successivo consiste nell'operazione di one-hot encoding, in modo da dummificare e rendere binari i valori 'object'
data_dummy = pd.get_dummies(data, drop_first=True, dtype=int)

data_dummy.head()

"""##  Analisi esplorativa dei dati"""

## Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(data_dummy.corr(), xticklabels=True, yticklabels=True)
plt.title("Matrice di correlazione completa")
plt.show()
print("\n\n")

# Notiamo che tutte le righe che finiscono con "No internet service" risultano essere ridondanti rispetto a "Internet Service".

## Analizziamo poi una heatmap esclusivamente incentrata sulla variabile target, per avere una visione più immediata
## delle variabili considerabili significative.
plt.figure(figsize=(8, 10))
sns.heatmap(data_dummy.corr()[["Churn"]], xticklabels=True, yticklabels=True, annot = True, fmt=".2f", vmin=-1, vmax=1)
plt.title("Correlazione delle feature con Churn")
plt.show()

## Scatterplot
plt.figure(figsize=(6, 5))
sns.scatterplot(data = data_dummy, x = "tenure", y = "MonthlyCharges", hue = "Churn", style= "Churn")
plt.show()
print("\n\n")

# Notiamo un pattern abbastanza definito - visualizziamo, per meglio comprenderlo, anche la correlazione con il tipo di contratto
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, contract_type in enumerate(data["Contract"].unique()):
    contract_data = data[data["Contract"] == contract_type]
    sns.scatterplot(data=contract_data, x="tenure", y="MonthlyCharges", hue="Churn", style="Churn", ax=axes[i], alpha=0.7, s=50,)
    axes[i].set_title(contract_type)
    axes[i].set_xlabel("Durata (tenure)")

    if i == 0:
        axes[i].set_ylabel("Monthly Charges")
    else:
        axes[i].set_ylabel("")

    if i > 0:
        axes[i].get_legend().remove()

plt.suptitle("La durata del contratto impatta sulla permanenza del cliente?", y=1.05, fontsize=14)
plt.tight_layout()
plt.subplots_adjust(top=0.85)
plt.show()

## Boxplot

# Per analizzare meglio queste relazioni attuamo una ricerca più specifica sulle variabili numeriche
# (non dummificate) rispetto a Churn, realizzando dei boxplot.

### 1. MonthlyCharges
sns.boxplot(x = "Churn", y = "MonthlyCharges", data = data_dummy)
plt.title("Distribuzione dei costi mensili")
plt.show()
print("\n\n")

### 2. tenure
sns.boxplot(x = "Churn", y = "tenure", data = data_dummy)
plt.title("Distribuzione dei mesi di permanenza")
plt.show()

"""### Verifica del bilanciamento delle classi"""

# Visualizziamo alcune statistiche rilevanti per Churn
data.describe()[["Churn"]]

# La distribuzione nel dataset tra i clienti fidelizzati e i clienti che abbandonano il servizio difficilmente sarà equa:
print("Distribuzione Variabile Target [Churn]:")
print((data["Churn"].value_counts()/len(data_dummy)) * 100)

"""## Preparazione dati per addestramento"""

# Lista delle colonne che vogliamo rimuovere perché ridondanti

da_eliminare = ["OnlineSecurity_No internet service", "OnlineBackup_No internet service",
                "DeviceProtection_No internet service","TechSupport_No internet service",
                "StreamingTV_No internet service","StreamingMovies_No internet service",
                "MultipleLines_No phone service"]

# Creiamo il dataframe finale ottimizzato
data2 = data_dummy.drop(columns = da_eliminare)

print("Colonne rimosse:", da_eliminare)

# Definizione Features (X) e Target (y)
X = data2.drop("Churn", axis = 1)
y = data2["Churn"]

# Divisione del dataset training set e test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)
# stratify = y permette di mantenere la proporzione tra Churn=0 e Churn=1 all'interno degli insiemi di addestramento
# e di verifica. Altrimenti la distribuzione sarebbe casuale e non avremmo garanzia alcuna di un addestramento efficace.

"""### Normalizzazione"""

# Selezioniamo le features numeriche "continue" (con range ampio)
features_numeriche = ["tenure", "MonthlyCharges"]

# Selezioniamo un paio di features binarie per il confronto (già presenti come 0/1 nel dataset)
# Nota: "Churn" è il target, "SeniorCitizen" è una feature
features_binarie = ["SeniorCitizen", "Churn"]

# Uniamo le liste per analizzarle insieme
colonne_da_analizzare = features_numeriche + features_binarie

# Generiamo la tabella
statistiche = data[colonne_da_analizzare].describe()

print("STATISTICHE")
print(statistiche)
print("\n")

# Come tecnica di normalizzazione usiamo MinMaxScaler, la quale comprime le features originariamente numeriche entro
# un intervallo [0, 1], senza considerare le features dummyficate le quali già risiedono all'interno dello stesso intervallo.
# Evitiamo la tecnica [(dati - media)/varianza] (standardizzazione) perché non gode della stessa proprietà e diversi
# dati rimarrebbero al di fuori dell'intervallo [0, 1]. Questo potrebbe portare ad attribuire maggior peso a variabili
# che esulano dall'intervallo [0, 1].
# Vista la prevalente presenza di variabili dummyficate, meglio la MinMaxScaler.

scaler = MinMaxScaler()
X_train[features_numeriche] = scaler.fit_transform(X_train[features_numeriche])
X_test[features_numeriche] = scaler.transform(X_test[features_numeriche])

"""## 1. Modello Base - errore non bilanciato"""

# Creazione del modello
RLogistica = LogisticRegression()

# Addestramento
RLogistica.fit(X_train, y_train)

# Previsione ("Predict")
y_predetta = RLogistica.predict(X_test)

# Calcoliamo l'Accuracy, la Precision e la Recall per il confronto finale
acc = accuracy_score(y_test, y_predetta)
precision_base_nb = precision_score(y_test, y_predetta)
recall_base_nb = recall_score(y_test, y_predetta)

print(f"\nAccuratezza sul Test Set: {acc:.2%}")

# Generiamo la matrice di confusione
mc1 = confusion_matrix(y_test, y_predetta)

plt.figure(figsize=(6, 5))
sns.heatmap(mc1, annot=True, fmt="d", cmap="YlOrRd", cbar=False,
            xticklabels=["Resta", "Abbandona"], yticklabels=["Resta", "Abbandona"])
plt.title("Matrice di Confusione (Logistic Regression)")
plt.xlabel("Previsione del Modello")
plt.ylabel("Realtà")
plt.show()
print("\n")

# Calcoliamo la AUC per il confronto finale tra i modelli
AUC_b = roc_auc_score(y_test, y_predetta)

# Stampiamo il report
print("RIEPILOGO")
print(classification_report(y_test, y_predetta))

"""## 2. Modello Base - errore bilanciato"""

# 1. Creazione del modello
RLogistica2 = LogisticRegression(class_weight="balanced", random_state=42)

# 2. Addestramento
RLogistica2.fit(X_train, y_train)

# 3. Previsione ("Predict")
y_predetta_log = RLogistica2.predict(X_test)

# 4. Calcoliamo la Precision e la Recall per il confronto finale
precision_base_b = precision_score(y_test, y_predetta_log)
recall_base_b = recall_score(y_test, y_predetta_log)

# Generiamo la matrice di confusione
mc_bil = confusion_matrix(y_test, y_predetta_log)

plt.figure(figsize=(6, 5))
sns.heatmap(mc_bil, annot=True, fmt="d", cmap="YlOrRd", cbar=False,
            xticklabels=["Resta", "Abbandona"],
            yticklabels=["Resta", "Abbandona"])
plt.title("Matrice di Confusione (Logistic Regression)")
plt.xlabel("Previsione del Modello")
plt.ylabel("Realtà")
plt.show()
print("\n")

# Calcoliamo la AUC per il confronto finale tra i modelli
AUC_b1 = roc_auc_score(y_test, y_predetta_log)

# Stampiamo il report
print("RIEPILOGO")
print(classification_report(y_test, y_predetta_log))

"""## 3. Modello Base - Soglia Ottima"""

# 1. Creiamo il terzo modello
RLogistica3 = LogisticRegression(class_weight="balanced", random_state=42)

# 2. Ricorriamo alla cross-validation per non calcolare la soglia includendo il test set e causando una data leakage
y_prob_cv = cross_val_predict(RLogistica3, X_train, y_train, cv=5, method='predict_proba')[:, 1]

# 3. Calcolo soglia ottima:
soglie = np.linspace(0, 1, 100)
F2_scores = [fbeta_score(y_train, (y_prob_cv >= s).astype(int), beta=2) for s in soglie]
soglia_ottima_1 = soglie[np.argmax(F2_scores)]

# 4. Fit modello
RLogistica3.fit(X_train, y_train)

# 5. Predizione sul test set
y_prob = RLogistica3.predict_proba(X_test)[:, 1]
y_soglia = (y_prob >= soglia_ottima_1).astype(int)

# 6. Calcoliamo FPR e TPR
FPR, TPR, _ = roc_curve(y_test, y_soglia)

# 7. Visualizziamo AUC e soglia ottimale
AUC = roc_auc_score(y_test, y_soglia)
print(f"AUC Score: {AUC:.4f}")
print(f"Soglia Ottimale calcolata: {soglia_ottima_1:.4f}")

# 7. Visualizziamo la ROC
plt.figure(figsize=(6, 5))
plt.plot(FPR, TPR, label=f"AUC = {AUC:.2f}", color = "green")
plt.plot([0, 1], [0, 1], 'k:', label = "Scelta casuale")
plt.xlabel("FPR (Previsioni sbagliate sulla classe 1)")
plt.ylabel("TPR (Previsioni corrette sulla classe 1)")
plt.title("Curva ROC")
plt.legend()
plt.grid()
plt.show()
print("\n")

## Calcoliamo anche la Precision e la Recall, nonostante siano già presenti nel confronto finale, solo per riutilizzarle alla fine
precision_base_ott = precision_score(y_test, y_soglia)
recall_base_ott = recall_score(y_test, y_soglia)

# Generiamo la matrice di confusione
mc_soglia = confusion_matrix(y_test, y_soglia)

plt.figure(figsize=(6, 5))
sns.heatmap(mc_soglia, annot=True, fmt="d", cmap="YlOrRd", cbar=False,
            xticklabels=["Resta", "Abbandona"],
            yticklabels=["Resta", "Abbandona"])
plt.title("Matrice di Confusione (Logistic Regression)")
plt.xlabel("Previsione del Modello")
plt.ylabel("Realtà")
plt.show()
print("\n")

# report finale
print("RIEPILOGO")
print(classification_report(y_test, y_soglia))

"""## Creazione modelli "tematici"
"""

# Valutazione di modelli mirati su particolari features, divise per "area tematica"

gruppo_finanziario = ["MonthlyCharges", "Contract_One year", "Contract_Two year",
                      "PaymentMethod_Electronic check", "PaperlessBilling_Yes"]

gruppo_tecnico = ["InternetService_Fiber optic", "InternetService_No", "OnlineSecurity_Yes", "TechSupport_Yes"]

gruppo_demografico = ["SeniorCitizen", "Partner_Yes", "Dependents_Yes", "gender_Male"]

def valutazione_modello_tematico(X_train_tema, X_test_tema, y_train, y_test, nome_modello):

    print(f"ANALISI MODELLO: {nome_modello.upper()}")

    # 1. Definiamo il modello
    RLtematica = LogisticRegression(class_weight = "balanced", random_state = 42)

    # 2. Cross-validation e calcolo soglia
    y_prob_training = cross_val_predict(RLtematica, X_train_tema, y_train, cv=5, method='predict_proba')[:, 1]

    soglie_2 = np.linspace(0, 1, 100)
    F2_tema = [fbeta_score(y_train, (y_prob_training >= z).astype(int), beta=2) for z in soglie_2]
    soglia_ottima_2 = soglie_2[np.argmax(F2_tema)]

    # 3. Addestriamo il modello
    RLtematica.fit(X_train_tema, y_train)

    # 4. Calcoliamo la probabilità, ROC e AUC
    y_prob_2 = RLtematica.predict_proba(X_test_tema)[:, 1]
    FPR_2, TPR_2, _ = roc_curve(y_test, y_prob_2)
    AUC_2 = roc_auc_score(y_test, y_prob_2)

    # 5. Predizione con soglia ottimale
    y_pred_ottima = (y_prob_2 >= soglia_ottima_2).astype(int)

    # 6. Calcolo Precision e Recall (per la comparazione finale)
    recall_tema = recall_score(y_test, y_pred_ottima)
    precision_tema = precision_score(y_test, y_pred_ottima)

    # 7. Output Testuale
    print(f"AUC Score: {AUC_2:.4f}")
    print(f"Soglia Ottimale calcolata: {soglia_ottima_2:.4f}")
    print(f"precision (alla soglia ottima): {precision_tema:.2f}")
    print(f"recall (alla soglia ottima): {recall_tema:.2f}")
    print("\n Report di Classificazione (con soglia ottimizzata)")
    print(classification_report(y_test, y_pred_ottima))

    # 8. Matrice di Confusione
    mc_tema = confusion_matrix(y_test, y_pred_ottima)

    plt.figure(figsize=(6, 5))
    sns.heatmap(mc_tema, annot = True, fmt = "d", cmap = "YlOrRd", cbar = False,
                xticklabels=["Resta", "Abbandona"], yticklabels=["Resta", "Abbandona"])
    plt.title(f"Matrice di confusione - {nome_modello}\n(Soglia: {soglia_ottima_2:.4f})")
    plt.ylabel("Realtà")
    plt.xlabel("Previsione")
    plt.show()
    print("\n\n")

    return AUC_2, soglia_ottima_2, recall_tema, precision_tema

"""### 4. Modello Finanziario - Soglia Ottima"""

# Modello A: Finanziario
auc_fin, soglia_fin, recall_fin, precision_fin = valutazione_modello_tematico(X_train[gruppo_finanziario], X_test[gruppo_finanziario], y_train, y_test, "Gruppo Finanziario")

"""### 5. Modello Tecnico - Soglia Ottima"""

# Modello B: Tecnico
auc_tec, soglia_tec, recall_tec, precision_tec = valutazione_modello_tematico(X_train[gruppo_tecnico], X_test[gruppo_tecnico], y_train, y_test, "Gruppo Tecnico")

"""### 6. Modello Demografico - Soglia Ottima"""

# Modello C: Demografico
auc_demo, soglia_demo, recall_demo, precision_demo = valutazione_modello_tematico(X_train[gruppo_demografico], X_test[gruppo_demografico], y_train, y_test, "Gruppo Demografico")

"""### Confronto provvisorio fra tutti i modelli"""

print("CONFRONTO PROVV. (SOGLIA F2)      AUC | Recall | Precision\n")
print(f"1. Modello base non bilanciato:  {AUC_b:.2f} |  {recall_base_nb:.2f}  | {precision_base_nb:.2f}")
print(f"2. Modello base bilanciato:      {AUC_b1:.2f} |  {recall_base_b:.2f}  | {precision_base_b:.2f}")
print(f"3. Modello base SO:              {AUC:.2f} |  {recall_base_ott:.2f}  | {precision_base_ott:.2f}")
print(f"4. Modello finanziario SO:       {auc_fin:.2f} |  {recall_fin:.2f}  | {precision_fin:.2f}")
print(f"5. Modello tecnico SO:           {auc_tec:.2f} |  {recall_tec:.2f}  | {precision_tec:.2f}")
print(f"6. Modello demografico SO:       {auc_demo:.2f} |  {recall_demo:.2f}  | {precision_demo:.2f}")

